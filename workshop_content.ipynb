{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7d1901-79b7-489e-9e0f-1c562cca352d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# WiDS Intro to ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10873b1-8fd8-4753-8757-7b15040e78dd",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd #Import the pandas library: Pandas is a Python library for data analysis.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier # import the class DecisionTreeClassifier which implements the decision tree classifier\n",
    "\n",
    "%matplotlib inline\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2ff4b",
   "metadata": {},
   "source": [
    "## Data Source:\n",
    "- Suppose we are working on a Spotify Song recommendation system, we want to predict if a customer will like a given song or not based on the song's features.\n",
    "\n",
    "- Data Description:\n",
    "> A dataset of 2017 songs with attributes from Spotify's API. Each song is labeled \"1\" meaning I like it and \"0\" for songs I don't like. Let's build a classifier that could predict whether or not I would like a song. \n",
    "\n",
    "> The original dataset can be found here: \n",
    "https://www.kaggle.com/datasets/geomack/spotifyclassification\n",
    "\n",
    "<div>\n",
    "<img src=\"dataset-cover.jpeg\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b77b3-a8e6-4efc-8f17-b36bc96c6be9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Step 1: we will import the data using Panda's read_csv() function:\n",
    "- In the bracket, you must include the file path of the data.\n",
    "    - *Note: index_col=0, indicates what column of the csv to use as the indexes (row labels) of the dataframe. If the dataset doesn't have an id column, You generally don't have to specify that.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv(\"data.csv\", index_col = 0)\n",
    "spotify_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we split the dataset into train and test sets:\n",
    "> We divide our data into training and test set in the ratio 80:20 respectively (i.e if your input dataset has 100 rows, training data will be 80 rows randomly selected from the input, and test set will have the remaining 20 rows)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Golden Rule of Machine Learning\n",
    "\n",
    "Never mix training and test data together. Always isolate the test set, so that we can use the test set to make prediction and evaluate our model.\n",
    "> You can think of `train_df` as the Practice exams & `test_df` as the FINAL exam.\n",
    "\n",
    "Now lets look at some code:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train_df will contain 80% of the input data, test_df will contain 20% of the input data (flights_df)\n",
    "train_df, test_df = train_test_split(spotify_df, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1613/(1613 + 404) = 0.8\n",
    "train_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "c3e778f9-b504-4223-92d1-494713833eb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: Clean data\n",
    "Let's look at the dataset information to see if there are incomplete rows"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at `train_df.info()` gives us a rough idea about the features being numeric or textual and the number of `NaNs` in each feature:\n",
    "- Luckily, we don't have any null values in our data, as we can see below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba28425-ed73-45bf-9e16-aa246aa0b191",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5f9fa-7ca9-46db-9bc0-65674b607b87",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can see that song title, artist and target are categorical variables. Therefore we need to transform these into numeric variables.\n",
    "\n",
    "number dummy variables = # categories - 1\n",
    "\n",
    "### How can we do this in python?\n",
    "By Column transformer (will be introduced in the future), but if you are interested you could learn about it here: https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "<div>\n",
    "<img src=\"columntransformer.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "### For simplicity, We will remove the text features from the data and just understand the model using numeric features for now, Since textual features need some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=[\"song_title\", \"artist\"])\n",
    "test_df = test_df.drop(columns=[\"song_title\", \"artist\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we are ready to train our model!\n",
    "The next step is to build a model using a machine learning algorithm. There are a lot of algorithms out there. Each algorithm has its pros and cons in terms of the performance. For this workshop we will use a very simple algorithm called Decision Tree.\n",
    "- We don't have to program this algorithm, it's actually already implemented for us in the library called scikit-learn (you will see the library imported the class DecisionTreeClassifier which implements the decision tree classifier)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here we are separating the target (AKA, response variables, y variable..) from the features (AKA, independent variables,predictors,x variables..)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# features,target :will be usedFOR TRAINING, think about them as the Practise exams and their answer keys\n",
    "X_train,y_train = train_df.drop(columns=[\"target\"]), train_df['target']\n",
    "\n",
    "# features,target :will be used FOR TESTING, think about them as the FINAL exams and  answer keys\n",
    "X_test, y_test = test_df.drop(columns=[\"target\"]), test_df['target']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "6542bde4-6ce9-47b6-b102-2200722ee515",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's talk about Decision Tree. Our goal here is to determine weather the customer likes the song or not. We can use Decision Tree algorithm here for creating the model for classification problems like this one."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is a Decision Tree?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- classification model that predicts value of target based on learning simple \"rules\" that it obtained from the data pattern.\n",
    "Let us consider the following data:\n",
    "<div>\n",
    "<img src=\"img.png\" width=\"1000\"/>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is one possible tree for this problem.\n",
    "<div>\n",
    "<img src=\"DecisionTree.png\" width=\"1000\"/>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Pros of Decision Tree Classifier:**\n",
    "\n",
    "    - simple to understand\n",
    "    - easy to visualize\n",
    "    - generate understandable rules.\n",
    "    - perform classification without requiring much computation.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "    - less appropriate for estimation tasks where the goal is to predict the value of a continuous attribute.\n",
    "    - prone to errors in classification problems with many class and a relatively small number of training examples."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How can we build a decision tree model in python?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets fit the model:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We need to create an object, let's call it model, and set it to a new instance of Decision Tree Classifier.\n",
    "model = DecisionTreeClassifier()\n",
    "# next we need to train it, so it learns the patterns of the INPUT train-set & OUTPUT train-set. Recall the Golden Rule of ML.\n",
    "# The input is X_train, the output is y_train\n",
    "model.fit(X_train, y_train)\n",
    "# The output is just a visual for the model object you just fitted/trained."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Make Predictions\n",
    "After fitting the model, we can predict on the testing set, and also evaluate our decision tree by calculating its accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# combining the predicted value with the test data set:\n",
    "pred_result = test_df\n",
    "pred_result['predicted'] = predict.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Evaluate the model and make improvement on its performance (Accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predict)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> The test accuracy score is one of the metrics to see how our model generalize to unseen data (This is the key for Machine Learning: Our model should generalize well for new observations). We want our model to have high accuracy when predicting the test set, so we have more confident on the model accuracy after it's deployed to real world.\n",
    "\n",
    "### Improving the model accuracy by Hyperparameter tuning:\n",
    "Did some magic here to tune the parameter that goes into our DecisionTree Algorithm:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "results_dict = {\n",
    "    \"max_depth\": [],\n",
    "    \"mean_train_score\": [],\n",
    "    \"mean_cv_score\": []\n",
    "}\n",
    "\n",
    "for depth in range(1, 26):\n",
    "    model = DecisionTreeClassifier(max_depth=depth)\n",
    "    cv_score = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)\n",
    "    results_dict[\"max_depth\"].append(depth)\n",
    "    results_dict[\"mean_cv_score\"].append( np.mean(cv_score[\"test_score\"]))\n",
    "    results_dict[\"mean_train_score\"].append( np.mean(cv_score[\"train_score\"]))\n",
    "\n",
    "result_df = pd.DataFrame(results_dict)\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimized_depth = result_df[result_df.mean_cv_score == result_df.mean_cv_score.max()].iloc[0,0]\n",
    "model_optimized = DecisionTreeClassifier(max_depth = optimized_depth)\n",
    "model_optimized.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimized_depth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict = model_optimized.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In reality most classifiers will never have 100% accuracy. And indeed in our case it doesn't reach a 100% accuracy. This is just a quick demo to show you the Step 5 where further improvements on the model can be done using Hyperparameter tuning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "5e6a7daf-a3f7-42ba-af01-add4d1c0a9e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercis for you: Let's Dive into Some Python Codes Now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c6266-644d-4d20-85c9-84e4dd0fdc3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we are building a model on the iris flower dataset. Start by importing the datasets library from `sklearn`, and load the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaefd785-814d-44ba-8301-53f1e53d7e93",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Load dataset + create a dataframe of this iris dataset. (you can ignore this step)\n",
    "iris =  datasets.load_iris()\n",
    "data = pd.DataFrame({\n",
    "    'sepal_length': iris.data[:,0],\n",
    "    'sepal_width': iris.data[:,1],\n",
    "    'petal_length': iris.data[:,2],\n",
    "    'petal_width': iris.data[:,3],\n",
    "    'species': iris.target\n",
    "})\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's print the target and feature variable names just to make sure that we are using the right dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(iris.target_names)\n",
    "print(iris.feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now Please complete the `#TODO`s:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the `train_test_split` function to split variables into train and test set (Let's take 75% to training and 25% to testing), and train the model on the train set and perform predictions on the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(#TODO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the species of iris flower is what we are interested in classifying, we first separate columns accordingly into dependent and independent variables.\n",
    "Steps as follow:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Seperate cols to dependent and independent variables\n",
    "X_train, y_train = train_df.drop(columns=[\"species\"]), train_df[\"species\"]\n",
    "X_test, y_test = #TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create the classifier\n",
    "model = #TODO\n",
    "model.fit(#TODO)\n",
    "# make the prediction using the Decision Tree model with the test x values( hint: X_test)\n",
    "y_pred = model.predict(#TODO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "607d69e7-c521-40c5-a07b-9e50639eeb1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now examine the Decision tree model's accuracy using the actual y (species) value and the predicted values given by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29548437-e06b-45e2-ba51-ec4baf5712f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"The accuracy for Decision Tree model is: \", round(accuracy_score(y_test, y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74913b2a-c29e-4823-9f18-854e9fd58c23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And we say the accuracy is pretty high for such model! To make a prediction on a single observation, we can also use the `predict()` function.\n",
    "For example:  \n",
    "    - sepal length = 3  \n",
    "    - sepal width = 6  \n",
    "    - petal length = 6  \n",
    "    - petal width = 4  \n",
    "Now we can predict which type of the iris flower it is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6e926-ebcc-493a-aa93-f16171772754",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.predict([[3,6,6,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e00eac-b901-431c-acc1-f5482c7eb212",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, the output is 2, which indicates an iris type of Virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3e69b-fb31-4e31-bebc-1720d4507699",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"survey.jpg\" width=\"500\"/>\n",
    "</div>\n",
    "Congratulation! You have made it so far and know what a typical Decision Tree classifier in python looks like. Please spend a minute to fill out this post workshop survey. Your feedback means a lot to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
