{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7d1901-79b7-489e-9e0f-1c562cca352d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# WiDS Intro to ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10873b1-8fd8-4753-8757-7b15040e78dd",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd #Import the pandas library: Pandas is a Python library for data analysis.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    ")\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier # import the class DecisionTreeClassifier which implements the decision tree classifier\n",
    "\n",
    "%matplotlib inline\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2ff4b",
   "metadata": {},
   "source": [
    "## Data Source:\n",
    "- Suppose we are working on a Spotify Song recommendation system, we want to predict if a customer will like a given song or not based on the song's features.\n",
    "\n",
    "- Data Description:\n",
    "> A dataset of 2017 songs with attributes from Spotify's API. Each song is labeled \"1\" meaning I like it and \"0\" for songs I don't like. Let's build a classifier that could predict whether or not I would like a song. \n",
    "\n",
    "> The original dataset can be found here: \n",
    "https://www.kaggle.com/datasets/geomack/spotifyclassification\n",
    "\n",
    "<div>\n",
    "<img src=\"dataset-cover.jpeg\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b77b3-a8e6-4efc-8f17-b36bc96c6be9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Step 1: we will import the data using Panda's read_csv() function:\n",
    "- In the bracket, you must include the file path of the data.\n",
    "    - *Note: index_col=0, indicates what column of the csv to use as the indexes (row labels) of the dataframe. If the dataset doesn't have an id column, You generally don't have to specify that.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n0        0.0102         0.833       204600   0.434          0.021900    2   \n1        0.1990         0.743       326933   0.359          0.006110    1   \n2        0.0344         0.838       185707   0.412          0.000234    2   \n3        0.6040         0.494       199413   0.338          0.510000    5   \n4        0.1800         0.678       392893   0.561          0.512000    5   \n\n   liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n0    0.1650    -8.795     1       0.4310  150.062             4.0    0.286   \n1    0.1370   -10.401     1       0.0794  160.083             4.0    0.588   \n2    0.1590    -7.148     1       0.2890   75.044             4.0    0.173   \n3    0.0922   -15.236     1       0.0261   86.468             4.0    0.230   \n4    0.4390   -11.648     0       0.0694  174.004             4.0    0.904   \n\n   target      song_title            artist  \n0       1        Mask Off            Future  \n1       1         Redbone  Childish Gambino  \n2       1    Xanny Family            Future  \n3       1  Master Of None       Beach House  \n4       1  Parallel Lines       Junior Boys  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n      <th>target</th>\n      <th>song_title</th>\n      <th>artist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0102</td>\n      <td>0.833</td>\n      <td>204600</td>\n      <td>0.434</td>\n      <td>0.021900</td>\n      <td>2</td>\n      <td>0.1650</td>\n      <td>-8.795</td>\n      <td>1</td>\n      <td>0.4310</td>\n      <td>150.062</td>\n      <td>4.0</td>\n      <td>0.286</td>\n      <td>1</td>\n      <td>Mask Off</td>\n      <td>Future</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.1990</td>\n      <td>0.743</td>\n      <td>326933</td>\n      <td>0.359</td>\n      <td>0.006110</td>\n      <td>1</td>\n      <td>0.1370</td>\n      <td>-10.401</td>\n      <td>1</td>\n      <td>0.0794</td>\n      <td>160.083</td>\n      <td>4.0</td>\n      <td>0.588</td>\n      <td>1</td>\n      <td>Redbone</td>\n      <td>Childish Gambino</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0344</td>\n      <td>0.838</td>\n      <td>185707</td>\n      <td>0.412</td>\n      <td>0.000234</td>\n      <td>2</td>\n      <td>0.1590</td>\n      <td>-7.148</td>\n      <td>1</td>\n      <td>0.2890</td>\n      <td>75.044</td>\n      <td>4.0</td>\n      <td>0.173</td>\n      <td>1</td>\n      <td>Xanny Family</td>\n      <td>Future</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.6040</td>\n      <td>0.494</td>\n      <td>199413</td>\n      <td>0.338</td>\n      <td>0.510000</td>\n      <td>5</td>\n      <td>0.0922</td>\n      <td>-15.236</td>\n      <td>1</td>\n      <td>0.0261</td>\n      <td>86.468</td>\n      <td>4.0</td>\n      <td>0.230</td>\n      <td>1</td>\n      <td>Master Of None</td>\n      <td>Beach House</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.1800</td>\n      <td>0.678</td>\n      <td>392893</td>\n      <td>0.561</td>\n      <td>0.512000</td>\n      <td>5</td>\n      <td>0.4390</td>\n      <td>-11.648</td>\n      <td>0</td>\n      <td>0.0694</td>\n      <td>174.004</td>\n      <td>4.0</td>\n      <td>0.904</td>\n      <td>1</td>\n      <td>Parallel Lines</td>\n      <td>Junior Boys</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df = pd.read_csv(\"data.csv\", index_col = 0)\n",
    "spotify_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we split the dataset into train and test sets:\n",
    "> We divide our data into training and test set in the ratio 80:20 respectively (i.e if your input dataset has 100 rows, training data will be 80 rows randomly selected from the input, and test set will have the remaining 20 rows)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Golden Rule of Machine Learning\n",
    "\n",
    "Never mix training and test data together. Always isolate the test set, so that we can use the test set to make prediction and evaluate our model.\n",
    "> You can think of `train_df` as the Practice exams & `test_df` as the FINAL exam.\n",
    "\n",
    "Now lets look at some code:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#train_df will contain 80% of the input data, test_df will contain 20% of the input data (flights_df)\n",
    "train_df, test_df = train_test_split(spotify_df, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(1613, 16)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1613/(1613 + 404) = 0.8\n",
    "train_df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(404, 16)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "c3e778f9-b504-4223-92d1-494713833eb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: Clean data\n",
    "Let's look at the dataset information to see if there are incomplete rows"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at `train_df.info()` gives us a rough idea about the features being numeric or textual and the number of `NaNs` in each feature:\n",
    "- Luckily, we don't have any null values in our data, as we can see below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1613 entries, 1043 to 1231\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   acousticness      1613 non-null   float64\n",
      " 1   danceability      1613 non-null   float64\n",
      " 2   duration_ms       1613 non-null   int64  \n",
      " 3   energy            1613 non-null   float64\n",
      " 4   instrumentalness  1613 non-null   float64\n",
      " 5   key               1613 non-null   int64  \n",
      " 6   liveness          1613 non-null   float64\n",
      " 7   loudness          1613 non-null   float64\n",
      " 8   mode              1613 non-null   int64  \n",
      " 9   speechiness       1613 non-null   float64\n",
      " 10  tempo             1613 non-null   float64\n",
      " 11  time_signature    1613 non-null   float64\n",
      " 12  valence           1613 non-null   float64\n",
      " 13  target            1613 non-null   int64  \n",
      " 14  song_title        1613 non-null   object \n",
      " 15  artist            1613 non-null   object \n",
      "dtypes: float64(10), int64(4), object(2)\n",
      "memory usage: 214.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba28425-ed73-45bf-9e16-aa246aa0b191",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n1043      0.214000         0.638       196422   0.634           0.00000    6   \n907       0.000885         0.790       312000   0.427           0.44600   11   \n51        0.063800         0.700       224480   0.840           0.11200    7   \n1107      0.163000         0.817       207200   0.869           0.00226    6   \n1728      0.105000         0.563       235853   0.487           0.00000    2   \n\n      liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n1043    0.0866    -6.474     1       0.0468   92.097             4.0    0.445   \n907     0.0514   -11.361     0       0.0541  116.986             4.0    0.961   \n51      0.1410    -6.227     0       0.0292  132.475             4.0    0.745   \n1107    0.0497    -4.791     1       0.1800   96.029             4.0    0.560   \n1728    0.0884    -7.775     1       0.0234  142.530             3.0    0.248   \n\n      target               song_title          artist  \n1043       0  I Could Use a Love Song    Maren Morris  \n907        1                  Nothing            HNNY  \n51         1                The Chase  Future Islands  \n1107       0                  Bailame           Nacho  \n1728       0    I'll Make Love To You     Boyz II Men  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n      <th>target</th>\n      <th>song_title</th>\n      <th>artist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1043</th>\n      <td>0.214000</td>\n      <td>0.638</td>\n      <td>196422</td>\n      <td>0.634</td>\n      <td>0.00000</td>\n      <td>6</td>\n      <td>0.0866</td>\n      <td>-6.474</td>\n      <td>1</td>\n      <td>0.0468</td>\n      <td>92.097</td>\n      <td>4.0</td>\n      <td>0.445</td>\n      <td>0</td>\n      <td>I Could Use a Love Song</td>\n      <td>Maren Morris</td>\n    </tr>\n    <tr>\n      <th>907</th>\n      <td>0.000885</td>\n      <td>0.790</td>\n      <td>312000</td>\n      <td>0.427</td>\n      <td>0.44600</td>\n      <td>11</td>\n      <td>0.0514</td>\n      <td>-11.361</td>\n      <td>0</td>\n      <td>0.0541</td>\n      <td>116.986</td>\n      <td>4.0</td>\n      <td>0.961</td>\n      <td>1</td>\n      <td>Nothing</td>\n      <td>HNNY</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.063800</td>\n      <td>0.700</td>\n      <td>224480</td>\n      <td>0.840</td>\n      <td>0.11200</td>\n      <td>7</td>\n      <td>0.1410</td>\n      <td>-6.227</td>\n      <td>0</td>\n      <td>0.0292</td>\n      <td>132.475</td>\n      <td>4.0</td>\n      <td>0.745</td>\n      <td>1</td>\n      <td>The Chase</td>\n      <td>Future Islands</td>\n    </tr>\n    <tr>\n      <th>1107</th>\n      <td>0.163000</td>\n      <td>0.817</td>\n      <td>207200</td>\n      <td>0.869</td>\n      <td>0.00226</td>\n      <td>6</td>\n      <td>0.0497</td>\n      <td>-4.791</td>\n      <td>1</td>\n      <td>0.1800</td>\n      <td>96.029</td>\n      <td>4.0</td>\n      <td>0.560</td>\n      <td>0</td>\n      <td>Bailame</td>\n      <td>Nacho</td>\n    </tr>\n    <tr>\n      <th>1728</th>\n      <td>0.105000</td>\n      <td>0.563</td>\n      <td>235853</td>\n      <td>0.487</td>\n      <td>0.00000</td>\n      <td>2</td>\n      <td>0.0884</td>\n      <td>-7.775</td>\n      <td>1</td>\n      <td>0.0234</td>\n      <td>142.530</td>\n      <td>3.0</td>\n      <td>0.248</td>\n      <td>0</td>\n      <td>I'll Make Love To You</td>\n      <td>Boyz II Men</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5f9fa-7ca9-46db-9bc0-65674b607b87",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can see that song title, artist and target are categorical variables. Therefore we need to transform these into numeric variables.\n",
    "\n",
    "number dummy variables = # categories - 1\n",
    "\n",
    "### How can we do this in python?\n",
    "By Column transformer (will be introduced in the future), but if you are interested you could learn about it here: https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "<div>\n",
    "<img src=\"columntransformer.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "### For simplicity, We will remove the text features from the data and just understand the model using numeric features for now, Since textual features need some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=[\"song_title\", \"artist\"])\n",
    "test_df = test_df.drop(columns=[\"song_title\", \"artist\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we are ready to train our model!\n",
    "The next step is to build a model using a machine learning algorithm. There are a lot of algorithms out there. Each algorithm has its pros and cons in terms of the performance. For this workshop we will use a very simple algorithm called Decision Tree.\n",
    "- We don't have to program this algorithm, it's actually already implemented for us in the library called scikit-learn (you will see the library imported the class DecisionTreeClassifier which implements the decision tree classifier)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here we are separating the target (AKA, response variables, y variable..) from the features (AKA, independent variables,predictors,x variables..)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# features,target :will be usedFOR TRAINING, think about them as the Practise exams and their answer keys\n",
    "X_train,y_train = train_df.drop(columns=[\"target\"]), train_df['target']\n",
    "\n",
    "# features,target :will be used FOR TESTING, think about them as the FINAL exams and  answer keys\n",
    "X_test, y_test = test_df.drop(columns=[\"target\"]), test_df['target']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n1043      0.214000         0.638       196422   0.634          0.000000    6   \n907       0.000885         0.790       312000   0.427          0.446000   11   \n51        0.063800         0.700       224480   0.840          0.112000    7   \n1107      0.163000         0.817       207200   0.869          0.002260    6   \n1728      0.105000         0.563       235853   0.487          0.000000    2   \n...            ...           ...          ...     ...               ...  ...   \n126       0.107000         0.645       591707   0.924          0.026600   10   \n1586      0.033600         0.890       129187   0.891          0.000000    2   \n755       0.023300         0.824       299960   0.572          0.000008   11   \n1132      0.001390         0.613       189387   0.874          0.000002    2   \n1231      0.049500         0.547       187013   0.513          0.000000    0   \n\n      liveness  loudness  mode  speechiness    tempo  time_signature  valence  \n1043    0.0866    -6.474     1       0.0468   92.097             4.0    0.445  \n907     0.0514   -11.361     0       0.0541  116.986             4.0    0.961  \n51      0.1410    -6.227     0       0.0292  132.475             4.0    0.745  \n1107    0.0497    -4.791     1       0.1800   96.029             4.0    0.560  \n1728    0.0884    -7.775     1       0.0234  142.530             3.0    0.248  \n...        ...       ...   ...          ...      ...             ...      ...  \n126     0.0982    -7.697     0       0.0569   90.852             4.0    0.886  \n1586    0.0970    -5.542     1       0.0483  119.993             4.0    0.947  \n755     0.2080    -4.868     1       0.0652  153.977             4.0    0.669  \n1132    0.6560    -3.594     1       0.0697  108.038             4.0    0.532  \n1231    0.1810    -7.451     1       0.0309  110.540             4.0    0.262  \n\n[1613 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1043</th>\n      <td>0.214000</td>\n      <td>0.638</td>\n      <td>196422</td>\n      <td>0.634</td>\n      <td>0.000000</td>\n      <td>6</td>\n      <td>0.0866</td>\n      <td>-6.474</td>\n      <td>1</td>\n      <td>0.0468</td>\n      <td>92.097</td>\n      <td>4.0</td>\n      <td>0.445</td>\n    </tr>\n    <tr>\n      <th>907</th>\n      <td>0.000885</td>\n      <td>0.790</td>\n      <td>312000</td>\n      <td>0.427</td>\n      <td>0.446000</td>\n      <td>11</td>\n      <td>0.0514</td>\n      <td>-11.361</td>\n      <td>0</td>\n      <td>0.0541</td>\n      <td>116.986</td>\n      <td>4.0</td>\n      <td>0.961</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.063800</td>\n      <td>0.700</td>\n      <td>224480</td>\n      <td>0.840</td>\n      <td>0.112000</td>\n      <td>7</td>\n      <td>0.1410</td>\n      <td>-6.227</td>\n      <td>0</td>\n      <td>0.0292</td>\n      <td>132.475</td>\n      <td>4.0</td>\n      <td>0.745</td>\n    </tr>\n    <tr>\n      <th>1107</th>\n      <td>0.163000</td>\n      <td>0.817</td>\n      <td>207200</td>\n      <td>0.869</td>\n      <td>0.002260</td>\n      <td>6</td>\n      <td>0.0497</td>\n      <td>-4.791</td>\n      <td>1</td>\n      <td>0.1800</td>\n      <td>96.029</td>\n      <td>4.0</td>\n      <td>0.560</td>\n    </tr>\n    <tr>\n      <th>1728</th>\n      <td>0.105000</td>\n      <td>0.563</td>\n      <td>235853</td>\n      <td>0.487</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.0884</td>\n      <td>-7.775</td>\n      <td>1</td>\n      <td>0.0234</td>\n      <td>142.530</td>\n      <td>3.0</td>\n      <td>0.248</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>0.107000</td>\n      <td>0.645</td>\n      <td>591707</td>\n      <td>0.924</td>\n      <td>0.026600</td>\n      <td>10</td>\n      <td>0.0982</td>\n      <td>-7.697</td>\n      <td>0</td>\n      <td>0.0569</td>\n      <td>90.852</td>\n      <td>4.0</td>\n      <td>0.886</td>\n    </tr>\n    <tr>\n      <th>1586</th>\n      <td>0.033600</td>\n      <td>0.890</td>\n      <td>129187</td>\n      <td>0.891</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.0970</td>\n      <td>-5.542</td>\n      <td>1</td>\n      <td>0.0483</td>\n      <td>119.993</td>\n      <td>4.0</td>\n      <td>0.947</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>0.023300</td>\n      <td>0.824</td>\n      <td>299960</td>\n      <td>0.572</td>\n      <td>0.000008</td>\n      <td>11</td>\n      <td>0.2080</td>\n      <td>-4.868</td>\n      <td>1</td>\n      <td>0.0652</td>\n      <td>153.977</td>\n      <td>4.0</td>\n      <td>0.669</td>\n    </tr>\n    <tr>\n      <th>1132</th>\n      <td>0.001390</td>\n      <td>0.613</td>\n      <td>189387</td>\n      <td>0.874</td>\n      <td>0.000002</td>\n      <td>2</td>\n      <td>0.6560</td>\n      <td>-3.594</td>\n      <td>1</td>\n      <td>0.0697</td>\n      <td>108.038</td>\n      <td>4.0</td>\n      <td>0.532</td>\n    </tr>\n    <tr>\n      <th>1231</th>\n      <td>0.049500</td>\n      <td>0.547</td>\n      <td>187013</td>\n      <td>0.513</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.1810</td>\n      <td>-7.451</td>\n      <td>1</td>\n      <td>0.0309</td>\n      <td>110.540</td>\n      <td>4.0</td>\n      <td>0.262</td>\n    </tr>\n  </tbody>\n</table>\n<p>1613 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "1043    0\n907     1\n51      1\n1107    0\n1728    0\n       ..\n126     1\n1586    0\n755     1\n1132    0\n1231    0\nName: target, Length: 1613, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "6542bde4-6ce9-47b6-b102-2200722ee515",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's talk about Decision Tree. Our goal here is to determine weather the customer likes the song or not. We can use Decision Tree algorithm here for creating the model for classification problems like this one."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is a Decision Tree?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- classification model that predicts value of target based on learning simple \"rules\" that it obtained from the data pattern.\n",
    "Let us consider the following data:\n",
    "<div>\n",
    "<img src=\"img.png\" width=\"1000\"/>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is one possible tree for this problem.\n",
    "<div>\n",
    "<img src=\"DecisionTree.png\" width=\"1000\"/>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Pros of Decision Tree Classifier:**\n",
    "\n",
    "    - simple to understand\n",
    "    - easy to visualize\n",
    "    - generate understandable rules.\n",
    "    - perform classification without requiring much computation.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "    - less appropriate for estimation tasks where the goal is to predict the value of a continuous attribute.\n",
    "    - prone to errors in classification problems with many class and a relatively small number of training examples."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How can we build a decision tree model in python?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets fit the model:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to create an object, let's call it model, and set it to a new instance of Decision Tree Classifier.\n",
    "model = DecisionTreeClassifier()\n",
    "# next we need to train it, so it learns the patterns of the INPUT train-set & OUTPUT train-set. Recall the Golden Rule of ML.\n",
    "# The input is X_train, the output is y_train\n",
    "model.fit(X_train, y_train)\n",
    "# The output is just a visual for the model object you just fitted/trained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Make Predictions\n",
    "After fitting the model, we can predict on the testing set, and also evaluate our decision tree by calculating its accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n       1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n       1, 0, 1, 1, 0, 0, 1, 1])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# combining the predicted value with the test data set:\n",
    "pred_result = test_df\n",
    "pred_result['predicted'] = predict.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n210       0.827000         0.583       248213   0.776          0.000038    3   \n1068      0.422000         0.482       230832   0.739          0.000019    7   \n995       0.000005         0.566       123547   0.869          0.309000    0   \n1476      0.131000         0.522       210816   0.860          0.020900   10   \n683       0.055700         0.599       222160   0.677          0.000180   11   \n...            ...           ...          ...     ...               ...  ...   \n257       0.539000         0.689       171560   0.830          0.000000    8   \n477       0.233000         0.328       225627   0.827          0.005170    6   \n1192      0.056700         0.467       293533   0.564          0.000000    9   \n333       0.119000         0.716       263817   0.647          0.000014    1   \n1865      0.323000         0.661       186492   0.544          0.022200    7   \n\n      liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n210     0.2980    -5.293     1       0.0661  126.536             4.0    0.782   \n1068    0.4680    -5.476     1       0.0342  155.932             4.0    0.596   \n995     0.0503    -7.614     1       0.0335  129.948             4.0    0.656   \n1476    0.1220    -3.773     0       0.1450  128.019             4.0    0.263   \n683     0.4340    -6.328     1       0.0314  126.012             4.0    0.108   \n...        ...       ...   ...          ...      ...             ...      ...   \n257     0.0882    -8.774     1       0.0954  140.732             4.0    0.822   \n477     0.6320    -2.545     0       0.2520  103.127             4.0    0.709   \n1192    0.1940    -4.986     0       0.3530   81.966             4.0    0.304   \n333     0.1210    -4.008     1       0.0345  131.040             4.0    0.159   \n1865    0.0871   -11.193     1       0.0304  139.012             4.0    0.307   \n\n      target  predicted  \n210        1          1  \n1068       0          0  \n995        1          1  \n1476       0          0  \n683        1          0  \n...      ...        ...  \n257        1          1  \n477        1          0  \n1192       0          0  \n333        1          1  \n1865       0          1  \n\n[404 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n      <th>target</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>210</th>\n      <td>0.827000</td>\n      <td>0.583</td>\n      <td>248213</td>\n      <td>0.776</td>\n      <td>0.000038</td>\n      <td>3</td>\n      <td>0.2980</td>\n      <td>-5.293</td>\n      <td>1</td>\n      <td>0.0661</td>\n      <td>126.536</td>\n      <td>4.0</td>\n      <td>0.782</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.422000</td>\n      <td>0.482</td>\n      <td>230832</td>\n      <td>0.739</td>\n      <td>0.000019</td>\n      <td>7</td>\n      <td>0.4680</td>\n      <td>-5.476</td>\n      <td>1</td>\n      <td>0.0342</td>\n      <td>155.932</td>\n      <td>4.0</td>\n      <td>0.596</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>0.000005</td>\n      <td>0.566</td>\n      <td>123547</td>\n      <td>0.869</td>\n      <td>0.309000</td>\n      <td>0</td>\n      <td>0.0503</td>\n      <td>-7.614</td>\n      <td>1</td>\n      <td>0.0335</td>\n      <td>129.948</td>\n      <td>4.0</td>\n      <td>0.656</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1476</th>\n      <td>0.131000</td>\n      <td>0.522</td>\n      <td>210816</td>\n      <td>0.860</td>\n      <td>0.020900</td>\n      <td>10</td>\n      <td>0.1220</td>\n      <td>-3.773</td>\n      <td>0</td>\n      <td>0.1450</td>\n      <td>128.019</td>\n      <td>4.0</td>\n      <td>0.263</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>0.055700</td>\n      <td>0.599</td>\n      <td>222160</td>\n      <td>0.677</td>\n      <td>0.000180</td>\n      <td>11</td>\n      <td>0.4340</td>\n      <td>-6.328</td>\n      <td>1</td>\n      <td>0.0314</td>\n      <td>126.012</td>\n      <td>4.0</td>\n      <td>0.108</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>0.539000</td>\n      <td>0.689</td>\n      <td>171560</td>\n      <td>0.830</td>\n      <td>0.000000</td>\n      <td>8</td>\n      <td>0.0882</td>\n      <td>-8.774</td>\n      <td>1</td>\n      <td>0.0954</td>\n      <td>140.732</td>\n      <td>4.0</td>\n      <td>0.822</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>0.233000</td>\n      <td>0.328</td>\n      <td>225627</td>\n      <td>0.827</td>\n      <td>0.005170</td>\n      <td>6</td>\n      <td>0.6320</td>\n      <td>-2.545</td>\n      <td>0</td>\n      <td>0.2520</td>\n      <td>103.127</td>\n      <td>4.0</td>\n      <td>0.709</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1192</th>\n      <td>0.056700</td>\n      <td>0.467</td>\n      <td>293533</td>\n      <td>0.564</td>\n      <td>0.000000</td>\n      <td>9</td>\n      <td>0.1940</td>\n      <td>-4.986</td>\n      <td>0</td>\n      <td>0.3530</td>\n      <td>81.966</td>\n      <td>4.0</td>\n      <td>0.304</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>0.119000</td>\n      <td>0.716</td>\n      <td>263817</td>\n      <td>0.647</td>\n      <td>0.000014</td>\n      <td>1</td>\n      <td>0.1210</td>\n      <td>-4.008</td>\n      <td>1</td>\n      <td>0.0345</td>\n      <td>131.040</td>\n      <td>4.0</td>\n      <td>0.159</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1865</th>\n      <td>0.323000</td>\n      <td>0.661</td>\n      <td>186492</td>\n      <td>0.544</td>\n      <td>0.022200</td>\n      <td>7</td>\n      <td>0.0871</td>\n      <td>-11.193</td>\n      <td>1</td>\n      <td>0.0304</td>\n      <td>139.012</td>\n      <td>4.0</td>\n      <td>0.307</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>404 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Evaluate the model and make improvement on its performance (Accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6782178217821783"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predict)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> The test accuracy score is one of the metrics to see how our model generalize to unseen data (This is the key for Machine Learning: Our model should generalize well for new observations). We want our model to have high accuracy when predicting the test set, so we have more confident on the model accuracy after it's deployed to real world.\n",
    "\n",
    "### Improving the model accuracy by Hyperparameter tuning:\n",
    "Did some magic here to tune the parameter that goes into our DecisionTree Algorithm:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    max_depth  mean_train_score  mean_cv_score\n0           1          0.629744       0.620585\n1           2          0.702074       0.676405\n2           3          0.724184       0.678867\n3           4          0.745747       0.693126\n4           5          0.783771       0.703673\n5           6          0.818695       0.715440\n6           7          0.850658       0.712376\n7           8          0.878693       0.701192\n8           9          0.903973       0.694349\n9          10          0.927532       0.696197\n10         11          0.946338       0.677590\n11         12          0.960460       0.677598\n12         13          0.974512       0.679438\n13         14          0.982778       0.690603\n14         15          0.989736       0.677613\n15         16          0.992974       0.685676\n16         17          0.996762       0.688130\n17         18          0.997451       0.684457\n18         19          0.998140       0.686918\n19         20          0.998278       0.681301\n20         21          0.998278       0.686907\n21         22          0.998278       0.677628\n22         23          0.998278       0.678859\n23         24          0.998278       0.684441\n24         25          0.998278       0.683176",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max_depth</th>\n      <th>mean_train_score</th>\n      <th>mean_cv_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.629744</td>\n      <td>0.620585</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.702074</td>\n      <td>0.676405</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.724184</td>\n      <td>0.678867</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.745747</td>\n      <td>0.693126</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.783771</td>\n      <td>0.703673</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.818695</td>\n      <td>0.715440</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.850658</td>\n      <td>0.712376</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.878693</td>\n      <td>0.701192</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.903973</td>\n      <td>0.694349</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.927532</td>\n      <td>0.696197</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.946338</td>\n      <td>0.677590</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.960460</td>\n      <td>0.677598</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.974512</td>\n      <td>0.679438</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.982778</td>\n      <td>0.690603</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.989736</td>\n      <td>0.677613</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>0.992974</td>\n      <td>0.685676</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>0.996762</td>\n      <td>0.688130</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>0.997451</td>\n      <td>0.684457</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>0.998140</td>\n      <td>0.686918</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>0.998278</td>\n      <td>0.681301</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>0.998278</td>\n      <td>0.686907</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>0.998278</td>\n      <td>0.677628</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>0.998278</td>\n      <td>0.678859</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>0.998278</td>\n      <td>0.684441</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>0.998278</td>\n      <td>0.683176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {\n",
    "    \"max_depth\": [],\n",
    "    \"mean_train_score\": [],\n",
    "    \"mean_cv_score\": []\n",
    "}\n",
    "\n",
    "for depth in range(1, 26):\n",
    "    model = DecisionTreeClassifier(max_depth=depth)\n",
    "    cv_score = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)\n",
    "    results_dict[\"max_depth\"].append(depth)\n",
    "    results_dict[\"mean_cv_score\"].append( np.mean(cv_score[\"test_score\"]))\n",
    "    results_dict[\"mean_train_score\"].append( np.mean(cv_score[\"train_score\"]))\n",
    "\n",
    "result_df = pd.DataFrame(results_dict)\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=6)",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6)</pre></div></div></div></div></div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_depth = result_df[result_df.mean_cv_score == result_df.mean_cv_score.max()].iloc[0,0]\n",
    "model_optimized = DecisionTreeClassifier(max_depth = optimized_depth)\n",
    "model_optimized.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_depth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9473684210526315"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_optimized.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In reality most classifiers will never have 100% accuracy. And indeed in our case it doesn't reach a 100% accuracy. This is just a quick demo to show you the Step 5 where further improvements on the model can be done using Hyperparameter tuning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "5e6a7daf-a3f7-42ba-af01-add4d1c0a9e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercis for you: Let's Dive into Some Python Codes Now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c6266-644d-4d20-85c9-84e4dd0fdc3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we are building a model on the iris flower dataset. Start by importing the datasets library from `sklearn`, and load the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eaefd785-814d-44ba-8301-53f1e53d7e93",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   sepal_length  sepal_width  petal_length  petal_width  species\n0           5.1          3.5           1.4          0.2        0\n1           4.9          3.0           1.4          0.2        0\n2           4.7          3.2           1.3          0.2        0\n3           4.6          3.1           1.5          0.2        0\n4           5.0          3.6           1.4          0.2        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load dataset + create a dataframe of this iris dataset. (you can ignore this step)\n",
    "iris =  datasets.load_iris()\n",
    "data = pd.DataFrame({\n",
    "    'sepal_length': iris.data[:,0],\n",
    "    'sepal_width': iris.data[:,1],\n",
    "    'petal_length': iris.data[:,2],\n",
    "    'petal_width': iris.data[:,3],\n",
    "    'species': iris.target\n",
    "})\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's print the target and feature variable names just to make sure that we are using the right dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)\n",
    "print(iris.feature_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the `train_test_split` function to split variables into train and test set (Let's take 75% to training and 25% to testing), and train the model on the train set and perform predictions on the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data, test_size = 0.25)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the species of iris flower is what we are interested in classifying, we first separate columns accordingly into dependent and independent variables.\n",
    "Steps as follow:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Seperate cols to dependent and independent variables\n",
    "X_train, y_train = train_df.drop(columns=[\"species\"]), train_df[\"species\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"species\"]), test_df[\"species\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# create the classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make the prediction using the Decision Tree model\n",
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "607d69e7-c521-40c5-a07b-9e50639eeb1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now examine the Decision tree model's accuracy using the actual y (species) value and the predicted values given by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29548437-e06b-45e2-ba51-ec4baf5712f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for Decision Tree model is:  0.9737\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy for Decision Tree model is: \", round(accuracy_score(y_test, y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74913b2a-c29e-4823-9f18-854e9fd58c23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And we say the accuracy is pretty high for such model! To make a prediction on a single item, we can also use the `predict()` function.  \n",
    "For example:  \n",
    "    - sepal length = 3  \n",
    "    - sepal width = 6  \n",
    "    - petal length = 6  \n",
    "    - petal width = 4  \n",
    "Now we can predict which type of the iris flower it is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ecc6e926-ebcc-493a-aa93-f16171772754",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([2])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[3,6,6,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e00eac-b901-431c-acc1-f5482c7eb212",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, the output is 2, which indicates an iris type of Virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3e69b-fb31-4e31-bebc-1720d4507699",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"survey.jpg\" width=\"500\"/>\n",
    "</div>\n",
    "Congratulation! You have made it so far and know what a typical Decision Tree classifier in python looks like. Please spend a minute to fill out this post workshop survey. Your feedback means a lot to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
